<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Gianluigi Lopardo </title> <meta name="author" content="Gianluigi Lopardo"> <meta name="description" content="Personal website of Gianluigi Lopardo. Here you'll find information about my research, projects, and professional background. "> <meta name="keywords" content="data-scientist, machine-learning, artificial-intelligence, interpretability, sentometrics, gianluigi-lopardo"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?b3314a157a053fe17ef0660dee35c00d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.gianluigilopardo.science//"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about ðŸ¤Œ <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Gianluigi</span> Lopardo </h1> <p class="desc">Data Scientist | <a href="https://www.ecb.europa.eu/" rel="external nofollow noopener" target="_blank">European Central Bank</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpeg?3b03beb9b9cb5cb146b189384db5f2fa" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpeg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>International Policy Analysis</p> <p>European Central Bank</p> <p>Frankfurt am Main, Germany</p> </div> </div> <div class="clearfix"> <p>Hi there!ðŸ‘‹ I am Gianluigi, a <strong>data scientist</strong> working at the <a href="https://www.ecb.europa.eu/" rel="external nofollow noopener" target="_blank">European Central Bank</a>. I am currently researching <strong>AI/ML methods for economic research</strong> within the international policy analysis division of the ECB. Prior to this, I was a doctoral researcher at <a href="https://inria.fr/" rel="external nofollow noopener" target="_blank">Inria</a> and <a href="https://univ-cotedazur.fr/" rel="external nofollow noopener" target="_blank">UniversitÃ© CÃ´te dâ€™Azur</a>. My PhD thesis focused on the <strong>foundations of machine learning interpretability</strong>, under the supervision of <a href="https://sites.google.com/view/damien-garreau/home" rel="external nofollow noopener" target="_blank">Damien Garreau</a> and <a href="https://webusers.i3s.unice.fr/~precioso/" rel="external nofollow noopener" target="_blank">FrÃ©dÃ©ric Precioso</a>. Previously, I earned an MSc in <strong>mathematical engineering</strong> and a BSc in <strong>applied mathematics</strong>, both from <a href="https://www.polito.it/" rel="external nofollow noopener" target="_blank">Politecnico di Torino</a>.</p> <p>Drop me a line if youâ€™re ever in Frankfurt, Rome, or <a href="https://www.basilicataturistica.it/territori/brienza" rel="external nofollow noopener" target="_blank">Brienza</a>!</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Feb 13, 2025</th> <td> Check out <a href="https://hacktheact.streamlit.app/" rel="external nofollow noopener" target="_blank">Hack the Act</a>!: a RAG-based chatbot designed to demystify the <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai" rel="external nofollow noopener" target="_blank">EU AI Act</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 15, 2025</th> <td> My PhD thesis on the Foundations of Machine Learning interpretability is <a href="https://theses.hal.science/tel-04917007" rel="external nofollow noopener" target="_blank">publicly available</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 17, 2024</th> <td> Talk at the ECB AI in Economics workshop </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 03, 2024</th> <td> Talk at the ECB Machine Learning community </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 07, 2024</th> <td> Talk for <a href="https://www.cognizant.com/us/en/services/ai/ai-lab" rel="external nofollow noopener" target="_blank">Cognizantâ€™s AI Research Lab</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 14, 2024</th> <td> I successfully defended my PhD thesis on the Foundations of Machine Learning interpretability! ðŸ¥³ </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 01, 2024</th> <td> I started working for the International Policy Analysis Division of the <a href="https://www.ecb.europa.eu/" rel="external nofollow noopener" target="_blank">European Central Bank</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 21, 2024</th> <td> In Vienna for <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML 2024</a> (June 21-27) </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 02, 2024</th> <td> Visiting the <a href="https://www.uni-wuerzburg.de/" rel="external nofollow noopener" target="_blank">Julius-Maximilians-UniversitÃ¤t WÃ¼rzburg</a> (June 2-15) </td> </tr> <tr> <th scope="row" style="width: 20%">May 24, 2024</th> <td> Our <a href="https://arxiv.org/abs/2402.03485v1" rel="external nofollow noopener" target="_blank">paper</a> <em>Attention Meets Post-hoc Interpretability: A Mathematical Perspective</em> got accepted at <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML 2024</a>! ðŸ¥³ðŸ¥³ðŸ¥³ </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/" sizes="200px"> <img src="/assets/img/publication_preview/" class="preview z-depth-1 rounded" width="100%" height="auto" alt="" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lopardo2024foundation" class="col-sm-8"> <div class="title">Foundations of Machine Learning Interpretability</div> <div class="author"> <em>Gianluigi Lopardo</em> </div> <div class="periodical"> <em>UniversitÃ© CÃ´te dâ€™Azur</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://theses.hal.science/tel-04917007/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://theses.hal.science/tel-04917007v1/document" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>The rising use of complex Machine Learning (ML) models, especially in critical applications, has highlighted the urgent need for interpretability methods. Despite the variety of solutions proposed to explain automated algorithmic decisions, understanding their decision-making process remains a challenge. This manuscript investigates the interpretability of ML models, using mathematical analysis and empirical evaluation to compare existing methods and propose novel solutions.Our main focus is on post-hoc interpretability methods, which provide insights into the decision-making process of ML models post-training, independent of specific model architectures. We delve into Natural Language Processing (NLP), exploring techniques for explaining text models.We address a key challenge: interpretability methods can yield varied explanations even for simple models. This highlights a critical issue: the absence of a robust theoretical foundation for these methods. To address this issue, we use a rigorous theoretical framework to formally analyze existing interpretability techniques, assessing their behavior and limitations.Building on this, we propose a novel explainer to provide a more faithful and robust approach to interpreting text data models. We also engage with the debate on the effectiveness of attention weights as explanatory tools within powerful transformer architectures.Through this analysis, we expose the strengths and limitations of existing interpretability methods and pave the way for more reliable, theoretically grounded approaches. This will lead to a deeper understanding of how complex models make decisions, fostering trust and responsible deployment in critical ML applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">lopardo2024foundation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Foundations of Machine Learning Interpretability}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lopardo, Gianluigi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{UniversitÃ© CÃ´te d'Azur}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/" sizes="200px"> <img src="/assets/img/publication_preview/" class="preview z-depth-1 rounded" width="100%" height="auto" alt="" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lopardo2024attention" class="col-sm-8"> <div class="title">Attention Meets Post-hoc Interpretability: A Mathematical Perspective</div> <div class="author"> <em>Gianluigi Lopardo</em>,Â Frederic Precioso,Â andÂ Damien Garreau </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=wnkC5T11Z9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://openreview.net/pdf?id=wnkC5T11Z9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/gianluigilopardo/attention_meets_xai" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Attention-based architectures, in particular transformers, are at the heart of a technological revolution. Interestingly, in addition to helping obtain state-of-the-art results on a wide range of applications, the attention mechanism intrinsically provides meaningful insights on the internal behavior of the model. Can these insights be used as explanations? Debate rages on. In this paper, we mathematically study a simple attention-based architecture and pinpoint the differences between post-hoc and attention-based explanations. We show that they provide quite different results, and that, despite their limitations, post-hoc methods are capable of capturing more useful insights than merely examining the attention weights.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lopardo2024attention</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Attention Meets Post-hoc Interpretability: A Mathematical Perspective}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lopardo, Gianluigi and Precioso, Frederic and Garreau, Damien}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{International Conference on Machine Learning (ICML)}}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/" sizes="200px"> <img src="/assets/img/publication_preview/" class="preview z-depth-1 rounded" width="100%" height="auto" alt="" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lopardo2022anchors" class="col-sm-8"> <div class="title">A Sea of Words: An In-Depth Analysis of Anchors for Text Data</div> <div class="author"> <em>Gianluigi Lopardo</em>,Â Frederic Precioso,Â andÂ Damien Garreau </div> <div class="periodical"> <em>In International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v206/lopardo23a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.mlr.press/v206/lopardo23a/lopardo23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/gianluigilopardo/anchors_text_theory" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. After formalizing the algorithm for text classification, we present explicit results on different classes of models when the vectorization step is TF-IDF, and words are replaced by a fixed out-of-dictionary token when removed. Our inquiry covers models such as elementary if-then rules and linear classifiers. We then leverage this analysis to gain insights on the behavior of Anchors for any differentiable classifiers. For neural networks, we empirically show that the words corresponding to the highest partial derivatives of the model with respect to the input, reweighted by the inverse document frequencies, are selected by Anchors.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lopardo2022anchors</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{A Sea of Words: An In-Depth Analysis of Anchors for Text Data}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lopardo, Gianluigi and Precioso, Frederic and Garreau, Damien}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{International Conference on Artificial Intelligence and Statistics (AISTATS)}}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/" sizes="200px"> <img src="/assets/img/publication_preview/" class="preview z-depth-1 rounded" width="100%" height="auto" alt="" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lopardo2023fred" class="col-sm-8"> <div class="title">Faithful and Robust Local Interpretability for Textual Predictions</div> <div class="author"> <em>Gianluigi Lopardo</em>,Â Frederic Precioso,Â andÂ Damien Garreau </div> <div class="periodical"> <em>arXiv preprint arXiv:2311.01605</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2311.01605" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2311.01605" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/gianluigilopardo/fred" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED offers three key insights to explain a model prediction: (1) it identifies the minimal set of words in a document whose removal has the strongest influence on the prediction, (2) it assigns an importance score to each token, reflecting its influence on the modelâ€™s output, and (3) it provides counterfactual explanations by generating examples similar to the original document, but leading to a different prediction. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lopardo2023fred</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Faithful and Robust Local Interpretability for Textual Predictions}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lopardo, Gianluigi and Precioso, Frederic and Garreau, Damien}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2311.01605}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/" sizes="200px"> <img src="/assets/img/publication_preview/" class="preview z-depth-1 rounded" width="100%" height="auto" alt="" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lopardo2022smace" class="col-sm-8"> <div class="title">SMACE: A New Method for the Interpretability of Composite Decision Systems</div> <div class="author"> <em>Gianluigi Lopardo</em>,Â Damien Garreau,Â Frederic Precioso, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Greger Ottosson' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-26387-3_20" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2111.08749" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/gianluigilopardo/smace" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Interpretability is a pressing issue for decision systems. Many post hoc methods have been proposed to explain the predictions of a single machine learning model. However, business processes and decision systems are rarely centered around a unique model. These systems combine multiple models that produce key predictions, and then apply rules to generate the final decision. To explain such decisions, we propose the Semi-Model-Agnostic Contextual Explainer (SMACE), a new interpretability method that combines a geometric approach for decision rules with existing interpretability methods for machine learning models to generate an intuitive feature ranking tailored to the end user. We show that established model-agnostic approaches produce poor results on tabular data in this setting, in particular giving the same importance to several features, whereas SMACE can rank them in a meaningful way.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lopardo2022smace</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{SMACE: A New Method for the Interpretability of Composite Decision Systems}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lopardo, Gianluigi and Garreau, Damien and Precioso, Frederic and Ottosson, Greger}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Joint European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{325--339}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%67%69%61%6E%6C%75%69%67%69%6C%6F%70%61%72%64%6F@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/gianluigilopardo" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/gianluigilopardo" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=Ddns-QsAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://telegram.me/gigilopardo" title="telegram" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-telegram"></i></a> <a href="https://twitter.com/gigilopardo" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">Feel free to reach out to me through any of these channels. </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> Â© Copyright 2025 Gianluigi Lopardo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: March 10, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>